{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-24T05:41:49.533117Z",
     "start_time": "2026-01-24T05:41:49.462431Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "make_upper = RunnableLambda(lambda x: x.upper())\n",
    "make_lower = RunnableLambda(lambda x: x.lower())\n",
    "chain =  make_upper | StrOutputParser()\n",
    "result = chain.invoke(\"I am Gaja\")\n",
    "result"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I AM GAJA'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def case_conversion(text):\n",
    "    return text.upper()\n",
    "make_upper = RunnableLambda(case_conversion)\n",
    "chain =  make_upper | StrOutputParser()\n",
    "result = chain.invoke(\"I am Gaja\")\n",
    "result"
   ],
   "id": "1f9242f3cfb3ab23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG CHAIN",
   "id": "b733ffd89dc9a5f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T05:48:21.154910Z",
     "start_time": "2026-01-24T05:48:21.149164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "api = os.getenv('google_flash')"
   ],
   "id": "8e4a763650aa2bb8",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T07:59:37.679479Z",
     "start_time": "2026-01-24T07:59:37.072561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Rag Chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableMap, RunnableBranch\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=api,\n",
    "    temperature=0.7,\n",
    "    max_tokens=None,\n",
    ")\n",
    "\n",
    "template = '''\n",
    "Consider yourself as a poet and write a poem for given topic\n",
    "Topic : {topic}\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "parser = StrOutputParser()"
   ],
   "id": "fb4a106b30deb7fc",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T05:57:18.203030Z",
     "start_time": "2026-01-24T05:57:08.633181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rag_chain = prompt | llm | parser\n",
    "results = rag_chain.invoke({\"topic\":\"Computers\"})\n",
    "results"
   ],
   "id": "707254eca13daa2c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From silicon dreams, a new age unfurls,\\nA whispered command that re-shapes our worlds.\\nA titan born of logic, cold and keen,\\nBehind a luminous, ever-shifting screen.\\n\\nIt hums with purpose, a relentless drive,\\nWhere countless data points now swiftly thrive.\\nA boundless library, a mind unbound,\\nWhere every question quickly can be found.\\n\\nIt weaves a web, a vast, unseen design,\\nConnecting souls across the digital line.\\nFrom distant shores, a voice, a face, a glance,\\nA global village, in a pixel dance.\\n\\nThe artist finds new canvas, bright and bold,\\nThe bard composes sagas, to be told\\nIn rhythmic code, or melodies that soar,\\nUnlocking wonders never seen before.\\n\\nYet in its brilliance, shadows softly gleam,\\nA digital illusion, a waking dream.\\nFor human touch, a warmth it cannot hold,\\nAnd stories left, in real-time, untold.\\n\\nWe feed it hours, our attention's toll,\\nA silent hunger, claiming heart and soul.\\nAnd sometimes wonder, in its sterile light,\\nIf warmth is lost, for all this dazzling might.\\n\\nA mirror held, to what we wish to be,\\nOur grandest dreams, our stark futility.\\nA potent power, shaped by human hand,\\nTo build or break, across this fragile land.\\n\\nSo gaze upon this marvel, deep and vast,\\nA future forged, from fragments of the past.\\nThe Computer stands, a testament and plea,\\nTo wield its might, with wise humanity.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T07:56:13.187582Z",
     "start_time": "2026-01-24T07:56:07.606616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Super simple RAG that just returns relevant chunks\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 1. Setup documents\n",
    "knowledge_base = [\n",
    "    \"Python is a programming language created by Guido van Rossum.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Deep learning uses neural networks with multiple layers.\",\n",
    "    \"LangChain helps build applications with LLMs.\",\n",
    "    \"HuggingFace provides transformer models and datasets.\"\n",
    "]\n",
    "\n",
    "# 2. Create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# 3. Create vector store\n",
    "vectorstore = FAISS.from_texts(knowledge_base, embeddings)\n",
    "def rag_reterive(query):\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "    docs = retriever.invoke(query)\n",
    "    context = (\"\\n\").join(doc.page_content for doc in docs)\n",
    "    return context"
   ],
   "id": "5e534281e29dd8f0",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T07:59:49.169860Z",
     "start_time": "2026-01-24T07:59:47.326214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Use ONLY the context below to answer.\n",
    "If context is insufficient, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "rag_chain = (\n",
    "    RunnableParallel({\"context\": RunnableLambda(rag_reterive),\"question\":RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "question = \"what is huggingface\"\n",
    "answer = rag_chain.invoke(question)\n",
    "print(answer)"
   ],
   "id": "d94353d672c568f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace provides transformer models and datasets.\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T08:15:47.048902Z",
     "start_time": "2026-01-24T08:15:46.909442Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5e932baecc727d62",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[45]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchains\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "728b359ae76d8407"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
